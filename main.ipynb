{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "\n",
    "import os\n",
    "if not os.path.exists('results'):\n",
    "    os.mkdir('results')\n",
    "\n",
    "if not os.path.exists('results/MODEL'):\n",
    "    os.chdir('results')\n",
    "    os.mkdir('MODEL')\n",
    "    os.chdir('..')\n",
    "    \n",
    "if not os.path.exists('results/best'):\n",
    "    os.chdir('results')\n",
    "    os.mkdir('best')\n",
    "    os.chdir('..')\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from bayes_opt import BayesianOptimization \n",
    "import json\n",
    "\n",
    "import functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Deep-Learning Framework to Predict the Dynamics of a Human-Driven Vehicle based on the Road Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the main parameters are defined (for information, read the reference paper):\n",
    "- Track dataframe\n",
    "- Driver/Vehicle dataframe\n",
    "- List of features (primary, secondary and road features)\n",
    "- The parameters stride, dR, pR, tF\n",
    "- The batch size used during the Neural Network training\n",
    "- The number of laps covered by the training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the track dataset\n",
    "track_name = \"calabogie\"\n",
    "\n",
    "# Name of the driver/vehicle dataset\n",
    "dataset_name = \"Calabogie-Sportcar-Antonio-20_12_03.pkl\"\n",
    "\n",
    "# Load the track dataset\n",
    "trackMap = functions.load_track(track_name)\n",
    "\n",
    "# Load the driver/vehicle dataset\n",
    "df = functions.load_dataset(dataset_name)\n",
    "\n",
    "# All of the driver/vehicle/road features needed in the prediction framework\n",
    "driver_vehicle_road_features = ['chassis_accelerations.longitudinal',\n",
    "           'chassis_accelerations.lateral',\n",
    "           'chassis_velocities.yaw',\n",
    "           'chassis_accelerations.vertical',\n",
    "           'chassis_velocities.pitch',\n",
    "           'chassis_velocities.roll', \n",
    "           'driver_demands.brake',\n",
    "           'driver_demands.steering', \n",
    "           'driver_demands.steering_velocity',\n",
    "           'driver_demands.throttle', \n",
    "           'transmission.gear',\n",
    "           'relativeDistance',\n",
    "           'relativeYaw',\n",
    "           'chassis_velocities.lateral',\n",
    "           'chassis_velocities.longitudinal',\n",
    "           'chassis_velocities.vertical',\n",
    "           'Angle_banking', \n",
    "           'FirstDerZ', \n",
    "           'SecondDerZ', \n",
    "           'curvature2d', \n",
    "           'roadWidth']\n",
    "\n",
    "driver_vehicle_road_features.append('Session-Lap') # Session-Lap is needed to manage the dataset\n",
    "\n",
    "# All of the driver/vehicle features\n",
    "driver_vehicle_features = ['chassis_accelerations.longitudinal',\n",
    "           'chassis_accelerations.lateral',\n",
    "            'chassis_velocities.yaw',\n",
    "           'chassis_accelerations.vertical',\n",
    "           'chassis_velocities.pitch',\n",
    "           'chassis_velocities.roll', \n",
    "           'driver_demands.brake',\n",
    "           'driver_demands.steering', \n",
    "           'driver_demands.steering_velocity',\n",
    "           'driver_demands.throttle', \n",
    "           'transmission.gear',\n",
    "           'relativeDistance',\n",
    "           'relativeYaw',\n",
    "           'chassis_velocities.lateral',\n",
    "           'chassis_velocities.longitudinal',\n",
    "           'chassis_velocities.vertical']\n",
    "\n",
    "# The driver/vehicle features to predict (primary and secondary)\n",
    "prediction_features = ['chassis_accelerations.longitudinal',\n",
    "       'chassis_accelerations.lateral',\n",
    "       'chassis_velocities.yaw',\n",
    "       'chassis_accelerations.vertical',\n",
    "       'chassis_velocities.pitch',\n",
    "       'chassis_velocities.roll',\n",
    "       'driver_demands.brake',\n",
    "       'driver_demands.steering', \n",
    "       'driver_demands.steering_velocity',\n",
    "       'driver_demands.throttle',\n",
    "       'transmission.gear',\n",
    "       'relativeDistance',\n",
    "       'relativeYaw',\n",
    "       'chassis_velocities.lateral',\n",
    "       'chassis_velocities.longitudinal',\n",
    "       'chassis_velocities.vertical']\n",
    "\n",
    "# The primary features (the features of interest in the prediction problem)\n",
    "primary_features = ['chassis_accelerations.longitudinal',\n",
    "       'chassis_accelerations.lateral',\n",
    "       'chassis_velocities.yaw']\n",
    "\n",
    "# The road geometry features\n",
    "road_features = ['Angle_banking',\n",
    "                 'FirstDerZ',\n",
    "                 'SecondDerZ',\n",
    "                 'curvature2d',\n",
    "                 'roadWidth']\n",
    "\n",
    "# The stride in the windowing process\n",
    "stride = 1\n",
    "\n",
    "# The parameter d^R\n",
    "dR = 150 # in meters\n",
    "\n",
    "# The parameter p^R\n",
    "pR = 50\n",
    "\n",
    "# The parameter t^F (Prediction steps)\n",
    "tF = 30\n",
    "\n",
    "# The batch size used during training of the Neural Network\n",
    "batch_size = 64\n",
    "\n",
    "# The number of laps constituting the training, validation and test sets\n",
    "total_laps = df['Session-Lap'].nunique() # total laps in the dataset\n",
    "n_train = int(total_laps*0.85) # number of training laps\n",
    "n_test = 1 # number of test laps\n",
    "n_dev = total_laps-n_train-n_test # number of validation laps\n",
    "\n",
    "train_dev_test_laps = [n_train, n_dev, n_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute some utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, some minor utilities are run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder lists, so that the primary features are always first, and the order of the features is always the same in the different lists\n",
    "driver_vehicle_road_features = primary_features + [el for el in driver_vehicle_road_features if (primary_features.count(el)==0)]\n",
    "prediction_features = [el for el in driver_vehicle_road_features if (prediction_features.count(el)>0)]\n",
    "road_features = [el for el in driver_vehicle_road_features if (road_features.count(el)>0)]\n",
    "\n",
    "# Define the indices of the features\n",
    "driver_vehicle_indices = []\n",
    "for i in driver_vehicle_features:\n",
    "    driver_vehicle_indices.append(driver_vehicle_road_features.index(i))\n",
    "\n",
    "prediction_indices = []\n",
    "for i in prediction_features:\n",
    "    prediction_indices.append(driver_vehicle_road_features.index(i))\n",
    " \n",
    "road_features_extended = []\n",
    "for i in range(pR):\n",
    "    for j in road_features:\n",
    "        road_features_extended.append('future_' + j + '_' + str(i))\n",
    "        \n",
    "driver_vehicle_road_features.remove(\"Session-Lap\") \n",
    "driver_vehicle_road_features = driver_vehicle_road_features + road_features_extended + [\"Session-Lap\"] # I put \"Session-Lap\" field at the very end\n",
    "\n",
    "road_indices = []\n",
    "for i in road_features_extended:\n",
    "    road_indices.append(driver_vehicle_road_features.index(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store config parameters in a dictionary\n",
    "config_parameters = {}\n",
    "config_parameters['tF'] = tF\n",
    "config_parameters['df'] = df\n",
    "config_parameters['trackMap'] = trackMap\n",
    "config_parameters['road_features'] = road_features\n",
    "config_parameters['dR'] = dR\n",
    "config_parameters['pR'] = pR\n",
    "config_parameters['driver_vehicle_road_features'] = driver_vehicle_road_features\n",
    "config_parameters['stride'] = stride\n",
    "config_parameters['train_dev_test_laps'] = train_dev_test_laps\n",
    "config_parameters['driver_vehicle_indices'] = driver_vehicle_indices\n",
    "config_parameters['road_indices'] = road_indices\n",
    "config_parameters['prediction_indices'] = prediction_indices\n",
    "config_parameters['batch_size'] = batch_size\n",
    "config_parameters['primary_features'] = primary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, Bayesian optimisation is launched. The routine loads the hyperparameters defined at each iteration by the Bayesian optimisation algorithm (read the reference paper), and the previously defined parameters. Then, it builds the input matrices to be fed to the Neural Network, trains the Neural Network and saves the model weights. At the end of Bayesian optimisation, the best hyperparameter combination is saved in a dedicated file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prefix name of the files (the same must be defined in function functions.train_model)\n",
    "fileName = 'Data30red'\n",
    "\n",
    "# Configure   \n",
    "def train_model_launcher(r, w, tP, u_ed, xi, save_results=False, i=''):\n",
    "    bayes_opt_score = functions.train_model(r, w, tP, u_ed, xi, save_results=save_results, i=i, config_parameters=config_parameters)\n",
    "    return bayes_opt_score\n",
    "    \n",
    "optimizer = BayesianOptimization(f = train_model_launcher,\n",
    "                                 pbounds={'r': (0.25, 0.5),\n",
    "                                          'w': (0.0, 1.0), \n",
    "                                          'tP': (15, 40),\n",
    "                                          'u_ed': (70, 110), \n",
    "                                          'xi': (0.3, 0.5)\n",
    "                                         },\n",
    "                                  verbose=2)\n",
    "\n",
    "# Run\n",
    "optimizer.maximize(init_points=2, n_iter=10)\n",
    "\n",
    "# Save the optimiser\n",
    "pickle.dump(optimizer, open('results/best/optimizer_{}.pkl'.format(fileName), 'wb'))\n",
    "\n",
    "# Save the best hyperparameters in a dedicated file\n",
    "targets = [e['target'] for e in optimizer.res]\n",
    "best_index = targets.index(max(targets))\n",
    "params = optimizer.res[best_index]['params']\n",
    "\n",
    "params_fname = '{}_results_best_params.json'.format(fileName)\n",
    "with open(os.path.join('results/best', params_fname), 'w') as f:\n",
    "     json.dump(params, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, Cross-validation is used to assess the performance of the optimal model found with Bayesian optimisation. A CSV file reporting the scores on the different sets is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best hyperparameters of the Bayesian optimisation\n",
    "fileName = 'Data30red'\n",
    "params_fname = '{}_results_best_params.json'.format(fileName)\n",
    "with open(os.path.join('results/best', params_fname), 'r') as f:\n",
    "    params = json.load(f)\n",
    "    \n",
    "# Run cross-validation\n",
    "cv_steps = 10 # steps of Cross-validation\n",
    "for i in range(0, cv_steps):\n",
    "    train_model_launcher(r=params['r'],\n",
    "                    w=params['w'],\n",
    "                    tP=params['tP'],\n",
    "                    u_ed=params['u_ed'],\n",
    "                    xi=params['xi'],\n",
    "                    save_results=True,\n",
    "                    i=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions with the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the optimal model is applied to a random test set. Some plots are generated to show its prediction capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model with a random test set\n",
    "fileName = 'Data30red'\n",
    "model, test_dataset, x_test, meanv, stdv = functions.best_model(fileName, config_parameters=config_parameters)\n",
    "\n",
    "# Predict the behaviour of the model on the test set\n",
    "X_true = np.array([np.squeeze(i[0][0], axis=0) for i in test_dataset])[:,:,prediction_indices] # I calculate the past only for the values I predict, for the plots\n",
    "Y_true = np.array([np.squeeze(i[1], axis=0) for i in test_dataset])\n",
    "Y_pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot two random prediction horizons\n",
    "q = len(primary_features)\n",
    "random_plots = np.random.randint(Y_pred.shape[0], size=2)\n",
    "names = [\"Primary feat \" + str(el) for el in range(q)]\n",
    "means = meanv.head(q).values\n",
    "standards = stdv.head(q).values\n",
    "\n",
    "fig, ax = plt.subplots(3,2,figsize=(6,6), )\n",
    "for index,i in enumerate(random_plots):\n",
    "    for j in range(q):\n",
    "        current_ax = ax[j][index]\n",
    "\n",
    "        X_true2 = X_true[i,:,j]*standards[j]+means[j]\n",
    "        Y_true2 = Y_true[i,:,j]*standards[j]+means[j]\n",
    "        Y_pred2 = Y_pred[i,:,j]*standards[j]+means[j]\n",
    "        current_ax.plot(np.arange(X_true.shape[1]) ,X_true2, linewidth=2, linestyle='--', color='tab:green')\n",
    "        current_ax.plot(X_true.shape[1] + np.arange(Y_true.shape[1]) ,Y_true2, linewidth=2, color='tab:blue')\n",
    "        current_ax.plot(X_true.shape[1] + np.arange(Y_pred.shape[1]) ,Y_pred2, linewidth=2, color='tab:orange')\n",
    "                \n",
    "        if (index==0 and j==q-1):\n",
    "            current_ax.legend(labels=[\"Past\",\"Truth\",\"Prediction\"], fontsize=10)\n",
    "        if j==q-1:\n",
    "            current_ax.set_xlabel(\"Time steps\", fontsize=10)\n",
    "            \n",
    "        current_ax.set_ylabel(names[j], fontsize=10)\n",
    "        current_ax.grid(b=True, which='major', color='k', linestyle='-', alpha=0.1)\n",
    "        plt.xticks(fontsize=8)\n",
    "        plt.yticks(fontsize=8)\n",
    "    fig.subplots_adjust(hspace=0.20, wspace=0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the long-term prediction for the whole test set\n",
    "q = len(primary_features)\n",
    "random_plots = np.random.randint(Y_pred.shape[0], size=2)\n",
    "names = [\"Primary feat \" + str(el) for el in range(q)]\n",
    "means = meanv.head(q).values\n",
    "standards = stdv.head(q).values\n",
    "\n",
    "fig, ax = plt.subplots(3,1,figsize=(6,7))\n",
    "for j in range(q):\n",
    "    current_ax = ax[j]\n",
    "\n",
    "    X_true2 = X_true[:,-1,j]*standards[j]+means[j]\n",
    "    Y_true2 = Y_true[:,-1,j]*standards[j]+means[j]\n",
    "    Y_pred2 = Y_pred[:,-1,j]*standards[j]+means[j]\n",
    "\n",
    "    current_ax.plot(X_true.shape[1] + np.arange(Y_true2.shape[0]) ,Y_true2, linewidth=1.4)\n",
    "    current_ax.plot(X_true.shape[1] + np.arange(Y_pred2.shape[0]) ,Y_pred2, linewidth=1.4)\n",
    "   \n",
    "    if j==q-1:\n",
    "        current_ax.legend(labels=[\"Truth\",\"Prediction\"], fontsize=10)\n",
    "        current_ax.set_xlabel(\"Time steps\", fontsize=10)\n",
    "        \n",
    "    current_ax.set_ylabel(names[j], fontsize=10)\n",
    "    current_ax.grid(b=True, which='major', color='k', linestyle='-', alpha=0.1)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.yticks(fontsize=8)\n",
    "fig.subplots_adjust(hspace=0.25, wspace=0.38)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
